{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "M4RPQcIPbuyb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import AdditiveAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Attention, concatenate\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "LzO2g1NNchTO"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    (\"Hello\", \"Muraho\"),\n",
        "    (\"mwiriwe\", \"Good evening\"),\n",
        "    (\"How are you?\", \"Mumeze mute?\"),\n",
        "    (\"Good morning\", \"Mwaramutse\"),\n",
        "    (\"Thank you\", \"Murakoze\"),\n",
        "    (\"Goodbye\", \"Murabeho\"),\n",
        "]\n",
        "\n",
        "# Load and preprocess data\n",
        "def preprocess_data(data):\n",
        "    english_sentences, kinyarwanda_sentences = zip(*data)\n",
        "\n",
        "    tokenizer_eng = Tokenizer()\n",
        "    tokenizer_kin = Tokenizer()\n",
        "    tokenizer_eng.fit_on_texts(english_sentences)\n",
        "    tokenizer_kin.fit_on_texts(kinyarwanda_sentences)\n",
        "\n",
        "    english_sequences = tokenizer_eng.texts_to_sequences(english_sentences)\n",
        "    kinyarwanda_sequences = tokenizer_kin.texts_to_sequences(kinyarwanda_sentences)\n",
        "\n",
        "    max_eng_len = max(len(seq) for seq in english_sequences)\n",
        "    max_kin_len = max(len(seq) for seq in kinyarwanda_sequences)\n",
        "\n",
        "    english_padded = pad_sequences(english_sequences, maxlen=max_eng_len, padding='post')\n",
        "    kinyarwanda_padded = pad_sequences(kinyarwanda_sequences, maxlen=max_kin_len, padding='post')\n",
        "\n",
        "    return (english_padded, kinyarwanda_padded,\n",
        "            tokenizer_eng, tokenizer_kin,\n",
        "            max_eng_len, max_kin_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "BnALXMOucTLl"
      },
      "outputs": [],
      "source": [
        "def build_model(eng_vocab_size, kin_vocab_size, max_eng_len, max_kin_len):\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(max_eng_len,))\n",
        "    encoder_embedding = Embedding(input_dim=eng_vocab_size, output_dim=256)(encoder_inputs)\n",
        "    encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(max_kin_len,))\n",
        "    decoder_embedding = Embedding(input_dim=kin_vocab_size, output_dim=256)(decoder_inputs)\n",
        "    decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "    # Attention mechanism\n",
        "    attention = AdditiveAttention()\n",
        "    context_vector = attention([decoder_outputs, encoder_outputs])\n",
        "    decoder_combined_context = concatenate([context_vector, decoder_outputs])\n",
        "\n",
        "    # Output layer\n",
        "    output = Dense(kin_vocab_size, activation='softmax')(decoder_combined_context)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "yWPQlXqfcVX5"
      },
      "outputs": [],
      "source": [
        "def sequence_to_text(sequence, tokenizer):\n",
        "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "    return ' '.join([reverse_word_map.get(i, '') for i in sequence if i != 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "2eud1tm-ivXb"
      },
      "outputs": [],
      "source": [
        "def create_inference_models(model):\n",
        "    # Encoder model\n",
        "    encoder_inputs = model.input[0]  \n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.layers[4].output\n",
        "\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder model\n",
        "    decoder_inputs = model.input[1] \n",
        "    decoder_state_input_h = Input(shape=(256,), name=\"decoder_state_input_h\")\n",
        "    decoder_state_input_c = Input(shape=(256,), name=\"decoder_state_input_c\")  \n",
        "    encoder_output_input = Input(shape=(None, 256), name=\"encoder_output_input\")\n",
        "\n",
        "    # Embedding layer shared with the trained model\n",
        "    decoder_embedding = model.layers[3](decoder_inputs)  # reuse embedding layer\n",
        "\n",
        "    # Reuse the LSTM layer from the original model\n",
        "    decoder_lstm = model.layers[5]\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Attention mechanism\n",
        "    attention = model.layers[6]\n",
        "    context_vector = attention([decoder_outputs, encoder_output_input])\n",
        "\n",
        "    # Concatenate context vector with decoder outputs\n",
        "    decoder_combined_context = concatenate([context_vector, decoder_outputs])\n",
        "\n",
        "    # Dense layer (softmax prediction)\n",
        "    decoder_dense = model.layers[-1]\n",
        "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Decoder inference model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, decoder_state_input_h, decoder_state_input_c, encoder_output_input],\n",
        "        [decoder_outputs, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "GxIl6FojcYeu"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(input_sentence, encoder_model, decoder_model, tokenizer_eng, tokenizer_kin, max_eng_len, max_kin_len):\n",
        "    # Preprocess input sentence\n",
        "    input_seq = tokenizer_eng.texts_to_sequences([input_sentence])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_eng_len, padding='post')\n",
        "\n",
        "    # Encode the input sentence\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Initialize the target sequence with the start token\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = tokenizer_kin.word_index.get('<start>', 1) \n",
        "\n",
        "    translated_sentence = []\n",
        "    for _ in range(max_kin_len):\n",
        "        # Pass the target_seq, encoder_outputs, and decoder states into the decoder\n",
        "        output_tokens, state_h, state_c = decoder_model.predict(\n",
        "            [target_seq, state_h, state_c, encoder_outputs]\n",
        "        )\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = tokenizer_kin.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        print(f\"Predicted Token Index: {sampled_token_index}, Predicted Word: {sampled_word}\")\n",
        "\n",
        "        if sampled_word == '<end>' or sampled_word == '':\n",
        "            break\n",
        "\n",
        "        # Append the predicted word to the translated sentence\n",
        "        translated_sentence.append(sampled_word)\n",
        "\n",
        "        # Update the target sequence with the predicted word index\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    return ' '.join(translated_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "Y5v4VXbfq_ox"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(test_sentences, true_translations, encoder_model, decoder_model, tokenizer_eng, tokenizer_kin, max_eng_len, max_kin_len):\n",
        "    predictions = [translate_sentence(sent, encoder_model, decoder_model, tokenizer_eng, tokenizer_kin, max_eng_len, max_kin_len) for sent in test_sentences]\n",
        "    bleu_scores = [sentence_bleu([ref.split()], pred.split()) for ref, pred in zip(true_translations, predictions)]\n",
        "    avg_bleu = np.mean(bleu_scores)\n",
        "    return avg_bleu, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "GSrGfvrccaYb"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    english_padded, kinyarwanda_padded, tokenizer_eng, tokenizer_kin, max_eng_len, max_kin_len = preprocess_data(data)\n",
        "\n",
        "    eng_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "    kin_vocab_size = len(tokenizer_kin.word_index) + 1\n",
        "\n",
        "    model = build_model(eng_vocab_size, kin_vocab_size, max_eng_len, max_kin_len)\n",
        "\n",
        "    print(\"Model Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        [english_padded, kinyarwanda_padded[:, :-1]],\n",
        "        kinyarwanda_padded[:, 1:], \n",
        "        batch_size=32,\n",
        "        epochs=50,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    print(\"\\nCreating inference models...\")\n",
        "    # Create inference models\n",
        "    encoder_model, decoder_model = create_inference_models(model)\n",
        "\n",
        "    # Example translation\n",
        "    input_sentence = \"Hello\"\n",
        "    print(\"\\nTranslating:\")\n",
        "    print(\"English:\", input_sentence)\n",
        "    print(\"Kinyarwanda:\", translate_sentence(input_sentence, encoder_model, decoder_model, tokenizer_eng, tokenizer_kin, max_eng_len, max_kin_len))\n",
        "\n",
        "    # Example of evaluating the model\n",
        "    test_sentences = [\"Hello\", \"How are you?\"]\n",
        "    true_translations = [\"Muraho\", \"Mumeze mute?\"]\n",
        "    bleu_score, predictions = evaluate_model(test_sentences, true_translations, encoder_model, decoder_model, tokenizer_eng, tokenizer_kin, max_eng_len, max_kin_len)\n",
        "    print(\"\\nEvaluation:\")\n",
        "    print(\"Average BLEU score:\", bleu_score)\n",
        "    print(\"Predictions:\", predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p4EYfUqPfs2q",
        "outputId": "60a31a11-4785-424d-a065-ba46536a142c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_55\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_55\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_80            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_81            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> │ input_layer_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │ input_layer_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],         │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │ lstm_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ additive_attention_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>)       │                        │                │ lstm_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_41            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ additive_attention_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ lstm_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,617</span> │ concatenate_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_80            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_81            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_79 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m2,560\u001b[0m │ input_layer_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_80 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m2,304\u001b[0m │ input_layer_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_79 (\u001b[38;5;33mLSTM\u001b[0m)            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m),       │        \u001b[38;5;34m525,312\u001b[0m │ embedding_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_80 (\u001b[38;5;33mLSTM\u001b[0m)            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m),       │        \u001b[38;5;34m525,312\u001b[0m │ embedding_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],         │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │ lstm_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ additive_attention_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │            \u001b[38;5;34m256\u001b[0m │ lstm_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m)       │                        │                │ lstm_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_41            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ additive_attention_6[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ lstm_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m9\u001b[0m)           │          \u001b[38;5;34m4,617\u001b[0m │ concatenate_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,060,361</span> (4.04 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,060,361\u001b[0m (4.04 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,060,361</span> (4.04 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,060,361\u001b[0m (4.04 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.2500 - loss: 2.1934 - val_accuracy: 1.0000 - val_loss: 2.1587\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 2.1429 - val_accuracy: 1.0000 - val_loss: 2.1225\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.0903 - val_accuracy: 1.0000 - val_loss: 2.0813\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 2.0330 - val_accuracy: 1.0000 - val_loss: 2.0328\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.9686 - val_accuracy: 1.0000 - val_loss: 1.9748\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7500 - loss: 1.8946 - val_accuracy: 1.0000 - val_loss: 1.9049\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7500 - loss: 1.8088 - val_accuracy: 1.0000 - val_loss: 1.8207\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7500 - loss: 1.7087 - val_accuracy: 1.0000 - val_loss: 1.7198\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7500 - loss: 1.5927 - val_accuracy: 1.0000 - val_loss: 1.6000\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7500 - loss: 1.4600 - val_accuracy: 1.0000 - val_loss: 1.4600\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7500 - loss: 1.3129 - val_accuracy: 1.0000 - val_loss: 1.3008\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7500 - loss: 1.1583 - val_accuracy: 1.0000 - val_loss: 1.1282\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7500 - loss: 1.0101 - val_accuracy: 1.0000 - val_loss: 0.9555\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7500 - loss: 0.8856 - val_accuracy: 1.0000 - val_loss: 0.8044\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7500 - loss: 0.7935 - val_accuracy: 1.0000 - val_loss: 0.6940\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7500 - loss: 0.7215 - val_accuracy: 1.0000 - val_loss: 0.6291\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7500 - loss: 0.6477 - val_accuracy: 1.0000 - val_loss: 0.6048\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7500 - loss: 0.5620 - val_accuracy: 1.0000 - val_loss: 0.6153\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7500 - loss: 0.4702 - val_accuracy: 1.0000 - val_loss: 0.6565\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.3859 - val_accuracy: 1.0000 - val_loss: 0.7209\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.3205 - val_accuracy: 1.0000 - val_loss: 0.7887\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.2718 - val_accuracy: 0.5000 - val_loss: 0.8307\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.2248 - val_accuracy: 0.5000 - val_loss: 0.8301\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.1707 - val_accuracy: 1.0000 - val_loss: 0.7902\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.1172 - val_accuracy: 1.0000 - val_loss: 0.7268\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0760 - val_accuracy: 1.0000 - val_loss: 0.6583\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0501 - val_accuracy: 1.0000 - val_loss: 0.5979\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0353 - val_accuracy: 1.0000 - val_loss: 0.5511\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.5182\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 0.4974\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 0.4862\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.4825\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.4844\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.4906\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.5002\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.5123\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.5263\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5000 - val_loss: 0.5417\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5000 - val_loss: 0.5581\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 8.2413e-04 - val_accuracy: 0.5000 - val_loss: 0.5751\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 6.4821e-04 - val_accuracy: 0.5000 - val_loss: 0.5924\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 5.2131e-04 - val_accuracy: 0.5000 - val_loss: 0.6098\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 4.2822e-04 - val_accuracy: 0.5000 - val_loss: 0.6271\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 3.5879e-04 - val_accuracy: 0.5000 - val_loss: 0.6441\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 3.0605e-04 - val_accuracy: 0.5000 - val_loss: 0.6606\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 2.6535e-04 - val_accuracy: 0.5000 - val_loss: 0.6766\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 2.3343e-04 - val_accuracy: 0.5000 - val_loss: 0.6920\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.0815e-04 - val_accuracy: 0.5000 - val_loss: 0.7066\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 1.8769e-04 - val_accuracy: 0.5000 - val_loss: 0.7205\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.7101e-04 - val_accuracy: 0.5000 - val_loss: 0.7337\n",
            "\n",
            "Creating inference models...\n",
            "\n",
            "Translating:\n",
            "English: Hello\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "Predicted Token Index: 0, Predicted Word: \n",
            "Kinyarwanda: \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Predicted Token Index: 0, Predicted Word: \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Predicted Token Index: 5, Predicted Word: mute\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Predicted Token Index: 5, Predicted Word: mute\n",
            "\n",
            "Evaluation:\n",
            "Average BLEU score: 0.0\n",
            "Predictions: ['', 'mute mute']\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "   main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "PuWORk63jef4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
